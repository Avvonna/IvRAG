{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45adb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "db_path = os.getenv(\"DB_OLD_PATH\")\n",
    "upd_path = os.getenv(\"DB_PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e305c031",
   "metadata": {},
   "source": [
    "Делаем так, чтобы все фильтры можно было делать по ответам\n",
    "\n",
    "Для этого уводим MULTI -> SINGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f42b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(db_path, engine=\"fastparquet\")\n",
    "\n",
    "# !!! Выбираем только последнюю волну, в остальных надо чекать формулировки !!!\n",
    "# df = df[df[\"wave\"] == \"2025-03\"]\n",
    "\n",
    "# df - датасет со столбцами:\n",
    "# - wave: category\n",
    "# - respondent_id: int\n",
    "# - respondent_uid: int\n",
    "# - question: category\n",
    "# - answer: category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2eb32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_formatted_question(col: pd.Series):\n",
    "    \"\"\" Функция, разбивающая отформатированный вопрос на составные части \"\"\"\n",
    "    pattern = r\"^\\[(?P<tag>[^\\]]+)?\\]\\s*(?P<q_clean>[^@|]+)(?:\\s*@\\s*(?P<detail>[^|]+))?(?:\\s*\\|\\s*(?P<option>.+))?$\"\n",
    "\n",
    "    df = col.str.extract(pattern)\n",
    "    df = df.apply(lambda col: col.str.strip())\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_question_parts(\n",
    "    col: pd.Series,\n",
    "    out: list[str] = ['tag', 'q_clean']\n",
    "):\n",
    "    QS = _parse_formatted_question(col)\n",
    "\n",
    "    if \"type\" in out:\n",
    "        m_det = QS[\"detail\"].notna()\n",
    "        m_opt = QS[\"option\"].notna()\n",
    "\n",
    "        # MIX, SINGLE, MULTI\n",
    "        QS.loc[m_opt, \"type\"] = \"MULTI\"\n",
    "        QS.loc[m_det & ~ m_opt, \"type\"] = \"MIX\"\n",
    "        QS.loc[~ m_det & ~ m_opt, \"type\"] = \"SINGLE\"\n",
    "\n",
    "    return QS[out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac692cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_parts = get_question_parts(df[\"question\"].cat.categories.to_series(), [\"type\", \"tag\", \"q_clean\", \"detail\", \"option\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(\n",
    "    df, q_parts,\n",
    "    left_on=\"question\", right_index=True,\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18ddedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_multi = merged_df[\"type\"] == \"MULTI\"\n",
    "merged_df.loc[m_multi, \"answer_new\"] = merged_df.loc[m_multi, \"option\"]\n",
    "merged_df.loc[~ m_multi, \"answer_new\"] = merged_df.loc[~ m_multi, \"answer\"].astype(\"string\")\n",
    "\n",
    "merged_df.loc[:, \"question_new\"] = \"[\" + merged_df[\"tag\"] + \"] \" + merged_df[\"q_clean\"]\n",
    "m_detail = merged_df[\"detail\"].notna()\n",
    "m_option = merged_df[\"option\"].notna()\n",
    "\n",
    "merged_df.loc[m_detail, \"question_new\"] = merged_df.loc[m_detail, \"question_new\"] + \" @ \" + merged_df.loc[m_detail, \"detail\"]\n",
    "\n",
    "merged_df = merged_df[[\"wave\", \"respondent_id\", \"respondent_uid\", \"question_new\", \"answer_new\"]]\\\n",
    "    .rename(columns={\"question_new\": \"question\", \"answer_new\": \"answer\"})\n",
    "\n",
    "merged_df[\"question\"] = merged_df[\"question\"].astype(\"string\").astype(\"category\")\n",
    "merged_df[\"answer\"] = merged_df[\"answer\"].astype(\"string\").astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a3dfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_parquet(upd_path, engine=\"fastparquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
