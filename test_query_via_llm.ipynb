{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Optional, Any, Iterable, Literal, Tuple\n",
    "from pydantic import BaseModel, Field\n",
    "import logging\n",
    "from openai import OpenAI\n",
    "from utils import _retry_call, _get_structured_response, _parse_formatted_question\n",
    "from report_functions import _get_q_type, _create_pivot_for_question, _process_one_filter, find_top_matches\n",
    "\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "API_KEY = os.getenv(\"OR_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5a93e8",
   "metadata": {},
   "source": [
    "## Подготовка вопросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tranc_unique(x: set|list|pd.Series, thr: int = 15):\n",
    "#     if isinstance(x, pd.Series):\n",
    "#         unique = sorted(x.dropna().unique())\n",
    "#     elif isinstance(x, list):\n",
    "#         unique = sorted(set(x))\n",
    "#     elif isinstance(x, set):\n",
    "#         unique = sorted(x)\n",
    "#     else:\n",
    "#         raise ValueError\n",
    "#     if len(unique) > thr:\n",
    "#         return unique[:thr] + [\"...\"]\n",
    "#     return unique\n",
    "\n",
    "# df = pd.read_parquet(r\"D:\\WORK\\db_nomgnt_latest.parquet\", engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff781654",
   "metadata": {},
   "source": [
    "Фильтр по волне"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bc04fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wave = \"2025-03\"\n",
    "\n",
    "# df = df[df[\"wave\"] == wave]\n",
    "# df[\"question\"].drop_duplicates().to_excel(f\"questions_from_{wave}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a71722f",
   "metadata": {},
   "source": [
    "Фильтр по году начала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a09afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YEAR = 2020\n",
    "\n",
    "# waves = df[\"wave\"].cat.categories.to_series()\n",
    "# years = waves.str.split(\"-\").str.get(0).astype(int)\n",
    "# latest_waves = years[years >= YEAR].index\n",
    "\n",
    "# df = df[df[\"wave\"].isin(latest_waves)]\n",
    "\n",
    "# QAs = _parse_formatted_question(df[\"question\"].cat.categories.to_series(name=\"question\"))\n",
    "# ans = df.groupby(\"question\", observed=True).agg(\n",
    "#     answers=(\"answer\", lambda x: set(x.dropna()))\n",
    "# )\n",
    "# QAs = pd.concat([QAs, ans], axis=1, join=\"inner\")\n",
    "\n",
    "# QAs = QAs.groupby(\"q_clean\", observed=True).agg(\n",
    "#     details=(\"detail\", lambda x: tranc_unique(x, 30)),\n",
    "#     options=(\"option\", lambda x: tranc_unique(x, 30)),\n",
    "#     answers=(\"answers\", lambda x: tranc_unique(set().union(*x)))\n",
    "# ).reset_index()\n",
    "\n",
    "# QAs.to_excel(f\"questions_from_{YEAR}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab366485",
   "metadata": {},
   "source": [
    "## Ключ, модель и путь к вопросам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c57c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_path = \"questions_from_2025-03.xlsx\"\n",
    "\n",
    "qs = pd.read_excel(qs_path)\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10938c60",
   "metadata": {},
   "source": [
    "## Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eea8559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic-схемы результата\n",
    "\n",
    "class ScoredQuestion(BaseModel):\n",
    "    question: str = Field(..., description=\"Точная формулировка вопроса из базы\")\n",
    "    reason: str = Field(..., description=\"Почему этот вопрос полезен для ответа на запрос\")\n",
    "    relevance: float = Field(..., description=\"Оценка релевантности 0–100\")\n",
    "\n",
    "class RankedQuestions(BaseModel):\n",
    "    results: List[ScoredQuestion] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"Список релевантных вопросов с объяснениями и оценками\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5db661bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def extract_questions(\n",
    "    client: OpenAI,\n",
    "    model: str,\n",
    "    user_query: str,\n",
    "    all_questions: List[str],\n",
    "    temperature: float = 1.2,\n",
    "    retries: int = 3,\n",
    "    base_delay: float = 1.0,\n",
    ") -> str:\n",
    "    if not all_questions:\n",
    "        return \"Список вопросов пуст — выбирать нечего.\"\n",
    "\n",
    "    questions_block = \"\\n\".join(f\"{i+1}. {q}\" for i, q in enumerate(all_questions))\n",
    "\n",
    "    prompt = prompt = f\"\"\"\n",
    "Запрос пользователя: {user_query}\n",
    "\n",
    "Список доступных вопросов:\n",
    "{questions_block}\n",
    "\n",
    "---\n",
    "Инструкция:\n",
    "\n",
    "Проанализируй запрос и подбери релевантные вопросы из списка с оценкой релевантности (0-100).\n",
    "\n",
    "Формат вывода:\n",
    "\n",
    "**Рассуждение:**\n",
    "[Краткий анализ запроса: 2-3 предложения о том, что нужно пользователю]\n",
    "\n",
    "**Рекомендованные вопросы:**\n",
    "\n",
    "1. **[92/100]** \"[Исходная формулировка вопроса]\"\n",
    "   • **Обоснование:** [Почему вопрос напрямую отвечает на запрос]\n",
    "\n",
    "2. **[78/100]** \"[Исходная формулировка вопроса]\"\n",
    "   • **Обоснование:** [Как вопрос связан с ключевой темой]\n",
    "\n",
    "3. **[65/100]** \"[Исходная формулировка вопроса]\"\n",
    "   • **Обоснование:** [Какой контекст или смежную тему раскрывает]\n",
    "\n",
    "4. **[55/100]** \"[Исходная формулировка вопроса]\"\n",
    "   • **Обоснование:** [Чем может быть полезен для понимания]\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "    def _call():\n",
    "        resp = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        return resp.choices[0].message.content.strip()\n",
    "\n",
    "    return _retry_call(_call, retries=retries, base_delay=base_delay)\n",
    "\n",
    "def unite_questions(\n",
    "    client: OpenAI,\n",
    "    model: str,\n",
    "    extraction_text: str,\n",
    "    all_questions: List[str],\n",
    "    max_keep: Optional[int],\n",
    "    temperature: float = 1,\n",
    "    retries: int = 3,\n",
    "    base_delay: float = 1.0,\n",
    ") -> RankedQuestions:\n",
    "    \"\"\"\n",
    "    Принимает текст из extract_questions и ПОЛНЫЙ список формулировок.\n",
    "    Возвращает строго структурированный список (Pydantic) с точными формулировками из базы.\n",
    "\n",
    "    Требуется модель с поддержкой native structured output (Responses API -> parse).\n",
    "    \"\"\"\n",
    "    if not all_questions:\n",
    "        return RankedQuestions(results=[])\n",
    "\n",
    "    questions_block = \"\\n\".join(f\"{i+1}. {q}\" for i, q in enumerate(all_questions))\n",
    "    cap = \"Выбери столько, сколько действительно нужно.\"\n",
    "    if isinstance(max_keep, int) and max_keep > 0:\n",
    "        cap = f\"Максимум {max_keep} штук.\"\n",
    "\n",
    "    prompt = f\"\"\"Твоя задача — сопоставить результаты предыдущего шага с ТЕМИ ЖЕ точными формулировками из базы.\n",
    "\n",
    "ВХОД:\n",
    "- Текстовый отчёт предыдущего шага (с рекомендациями и оценками):\n",
    "\\\"\\\"\\\"{extraction_text}\\\"\\\"\\\"\n",
    "\n",
    "- Полный список ДОПУСТИМЫХ (ТОЧНЫХ) формулировок вопросов — выбор разрешён ТОЛЬКО из него:\n",
    "{questions_block}\n",
    "\n",
    "ТРЕБОВАНИЯ:\n",
    "- Поле results — список уникальных элементов.\n",
    "- Для каждого элемента:\n",
    "  - question — ТОЧНАЯ формулировка из списка выше (обязательно одно из перечисленных).\n",
    "  - reason — сжато, своими словами, почему он уместен.\n",
    "  - relevance — число 0–100 (можно скорректировать оценки из отчёта).\n",
    "- {cap}\n",
    "- Если соответствия неочевидны, выбери наиболее близкую по смыслу формулировку ИЗ СПИСКА.\n",
    "- Никаких формулировок вне списка.\n",
    "\n",
    "Верни только структурированный объект.\n",
    "\"\"\"\n",
    "\n",
    "    parsed: RankedQuestions = _get_structured_response(\n",
    "        client=client,\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        response_model=RankedQuestions,\n",
    "        temperature=temperature,\n",
    "        retries=retries,\n",
    "        base_delay=base_delay,\n",
    "    )\n",
    "\n",
    "    # Валидация ответов\n",
    "    valid_set = set(all_questions)\n",
    "    unique = []\n",
    "    seen = set()\n",
    "    for item in parsed.results:\n",
    "        q = (item.question or \"\").strip()\n",
    "        if not q or q not in valid_set or q in seen:\n",
    "            logger.warning(f\"Пропущено: '{q[:60]}...' (неточного соответствия или дубликат)\")\n",
    "            continue\n",
    "        seen.add(q)\n",
    "        # нормируем диапазон на всякий случай\n",
    "        score = max(0.0, min(100.0, float(item.relevance)))\n",
    "        unique.append(ScoredQuestion(question=q, reason=item.reason.strip(), relevance=score))\n",
    "\n",
    "    return RankedQuestions(results=unique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e0a8c",
   "metadata": {},
   "source": [
    "## Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b65ff1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопросов: 1384\n"
     ]
    }
   ],
   "source": [
    "questions = qs[\"question\"].to_list()\n",
    "print(f\"Вопросов: {len(questions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ba07d2",
   "metadata": {},
   "source": [
    "### Уточняем по запросу пользователя какие вопросы нужны"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f57ac8",
   "metadata": {},
   "source": [
    "### Вытаскиваем вопросы в свободной форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48849f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Рассуждение:**  \n",
      "Пользователю требуется рассчитать средний размер сбережений и норму сбережений среди респондентов, у которых такие сбережения есть. Нужны вопросы, содержащие данные о наличии сбережений, их величине и доле сберегаемого дохода.\n",
      "\n",
      "**Рекомендованные вопросы:**\n",
      "\n",
      "1. **[44] [95/100]** \"[N3] Как бы Вы охарактеризовали величину сбережений Вашей семьи?\"  \n",
      "   • **Обоснование:** Напрямую оценивает качественные характеристики сбережений (например, \"маленькие\", \"большие\"), что можно использовать для категоризации респондентов, *у кого сбережения есть*.\n",
      "\n",
      "2. **[45] [100/100]** \"[A26] Каков размер денежных сбережений Вашей семьи (наличные деньги, депозиты в банках, ценные бумаги)?\"  \n",
      "   • **Обоснование:** Прямой вопрос о количественном размере сбережений. Незаменим для расчета средних значений среди тех, у кого есть сбережения.\n",
      "\n",
      "3. **[46] [95/100]** \"[N4] Какой % от Вашего дохода Вы сберегаете ежемесячно?\"  \n",
      "   • **Обоснование:** Замеряет норму сбережений — ключевой показатель для запроса. Респондентов с нулевыми сбережениями можно исключить из выборки.\n",
      "\n",
      "4. **[42] [65/100]** \"[Q16] К какому экономическому классу Вы себя относите?\"  \n",
      "   • **Обоснование:** Позволит косвенно проверить корреляцию социально-экономического статуса с уровнем сбережений. Контекстно полезно для анализа данных.\n",
      "\n",
      "5. **[88] [55/100]** \"[J6] Как часто Вы покупаете продукты питания (без учета онлайн-заказов)?\"  \n",
      "   • **Обоснование:** Может отражать паттерны экономии на повседневных расходах, влияющие на норму сбережений. Пригодится для углубленного анализа.\n"
     ]
    }
   ],
   "source": [
    "user_query = \"Посчитай мне размер средних сбережений и норму сбережний среди тех респондентов, у которых они есть.\"\n",
    "\n",
    "extract_text = extract_questions(\n",
    "    client,\n",
    "    model=\"tngtech/deepseek-r1t2-chimera:free\",\n",
    "    user_query=user_query,\n",
    "    all_questions=questions,\n",
    ")\n",
    "print(extract_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26df839",
   "metadata": {},
   "source": [
    "### Вытаскиваем вопросы с жесткой привязкой к модели Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "697772c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'question': '[N3] Как бы Вы охарактеризовали величину сбережений Вашей семьи?', 'reason': 'Прямая оценка качественных характеристик сбережений', 'relevance': 95.0}, {'question': '[A26] Каков размер денежных сбережений Вашей семьи (наличные деньги, депозиты в банках, ценные бумаги)?', 'reason': 'Прямая количественная оценка сбережений', 'relevance': 100.0}, {'question': '[N4] Какой % от Вашего дохода Вы сберегаете ежемесячно?', 'reason': 'Оценка нормы сбережений', 'relevance': 95.0}, {'question': '[Q16] К какому экономическому классу Вы себя относите?', 'reason': 'Косвенная оценка социально-экономического статуса', 'relevance': 65.0}, {'question': '[J6] Как часто Вы покупаете продукты питания (без учета онлайн-заказов)?', 'reason': 'Оценка паттернов экономии на повседневных расходах', 'relevance': 55.0}]}\n"
     ]
    }
   ],
   "source": [
    "ranked = unite_questions(\n",
    "    client,\n",
    "    model=\"meta-llama/llama-4-maverick:free\",\n",
    "    # model=\"meta-llama/llama-3.3-8b-instruct:free\",\n",
    "    extraction_text=extract_text,\n",
    "    all_questions=questions,\n",
    "    max_keep=100\n",
    ")\n",
    "print(ranked.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ede8b6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[N3] Как бы Вы охарактеризовали величину сбережений Вашей семьи?',\n",
       " '[A26] Каков размер денежных сбережений Вашей семьи (наличные деньги, депозиты в банках, ценные бумаги)?',\n",
       " '[N4] Какой % от Вашего дохода Вы сберегаете ежемесячно?',\n",
       " '[Q16] К какому экономическому классу Вы себя относите?',\n",
       " '[J6] Как часто Вы покупаете продукты питания (без учета онлайн-заказов)?']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_qs = [sq.question for sq in ranked.results]\n",
    "chosen_qs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4844f",
   "metadata": {},
   "source": [
    "## Tool для LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cafef452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = r\"D:\\WORK\\db_nomgnt_latest.parquet\"\n",
    "ext_path = r\"D:\\WORK\\data\\EXT\\EXT_data.xlsx\"\n",
    "\n",
    "df = pd.read_parquet(df_path, engine=\"fastparquet\")\n",
    "df_QS = df[\"question\"].cat.categories.to_frame(name=\"question\")\n",
    "df_QS[[\"type\", \"option\"]] = _get_q_type(df_QS[\"question\"])\n",
    "\n",
    "df_ext = pd.read_parquet(ext_path, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceef4fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _select_questions(\n",
    "    df_QS: pd.DataFrame,\n",
    "    queries: str | Iterable[str],\n",
    "    *,\n",
    "    exact: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Возвращает подтаблицу df_QS с вопросами, подходящими под шаблон(ы).\n",
    "\n",
    "    - queries: один шаблон или список шаблонов. Если exact=False, то используется contains (без regex),\n",
    "      иначе — строгие совпадения по \"question\".\n",
    "    \"\"\"\n",
    "    if isinstance(queries, str):\n",
    "        queries = [queries]\n",
    "    queries = list(queries)\n",
    "\n",
    "    parts: list[pd.DataFrame] = []\n",
    "    for q in queries:\n",
    "        if exact:\n",
    "            parts.append(df_QS[df_QS[\"question\"].isin([q])])\n",
    "        else:\n",
    "            parts.append(df_QS[df_QS[\"question\"].str.contains(q, regex=False)])\n",
    "    if not parts:\n",
    "        return df_QS.iloc[0:0]\n",
    "    out = pd.concat(parts, axis=0).drop_duplicates(ignore_index=True)\n",
    "    return out\n",
    "\n",
    "def _combine_filters(\n",
    "    DB: pd.DataFrame,\n",
    "    df_QS: pd.DataFrame,\n",
    "    df_ext: pd.DataFrame | None,\n",
    "    filters: Iterable[Tuple[str, str, Literal[\"AND\", \"OR\"]]] | None,\n",
    "    waves: Iterable[str] | None,\n",
    "    *,\n",
    "    verbose: int = 1,\n",
    ") -> tuple[pd.DataFrame | None, list[Tuple[str, str, str]]]:\n",
    "    \"\"\"Повторяет логику _filter_df, но принимает структурированный список фильтров.\n",
    "\n",
    "    filters: список троек (question, value|\"CHECKED\"|TOWNSIZE_value, logic)\n",
    "    waves: если передан, то отфильтровывает DB по волнам ДО применения фильтров по вопросам.\n",
    "    Возвращает (filtered_df | None, applied_filters | []).\n",
    "    \"\"\"\n",
    "    if filters is None:\n",
    "        filters = []\n",
    "    filters = list(filters)\n",
    "\n",
    "    if waves is not None:\n",
    "        waves = list(waves)\n",
    "        DB = DB[DB[\"wave\"].isin(waves)]\n",
    "\n",
    "    if not filters:\n",
    "        return DB, []\n",
    "\n",
    "    mask = pd.Series(True, index=DB.index)\n",
    "    problem_flag = False\n",
    "    applied: list[Tuple[str, str, str]] = []\n",
    "\n",
    "    for q, v, t in filters:\n",
    "        cur_mask = _process_one_filter(DB, df_QS, df_ext, q, v, verbose)\n",
    "        if cur_mask is None:\n",
    "            problem_flag = True\n",
    "            continue\n",
    "        if t == \"AND\":\n",
    "            mask &= cur_mask\n",
    "        elif t == \"OR\":\n",
    "            mask |= cur_mask\n",
    "        else:\n",
    "            problem_flag = True\n",
    "            if verbose >= 1:\n",
    "                print(f\"!!! Допустимые значения операций: AND, OR (дано - '{t}')\")\n",
    "            continue\n",
    "        applied.append((q, v, t))\n",
    "\n",
    "    if problem_flag:\n",
    "        return None, []\n",
    "\n",
    "    if mask.sum() == 0:\n",
    "        if verbose >= 1:\n",
    "            print(\"!!! По указанным фильтрам нет респондентов\")\n",
    "        return None, []\n",
    "\n",
    "    uids = DB.loc[mask, \"respondent_uid\"].unique().tolist()\n",
    "    return DB.loc[DB[\"respondent_uid\"].isin(uids)], applied\n",
    "\n",
    "def _process_crosstab(\n",
    "    DB_filtered: pd.DataFrame,\n",
    "    df_QS: pd.DataFrame,\n",
    "    rows_qs: pd.DataFrame,\n",
    "    cols_qs: pd.DataFrame,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Кросстаб по двум вопросам (строки × столбцы).\n",
    "\n",
    "    Поведение процентовки аналогично _process_q: проценты считаются по столбцам,\n",
    "    знаменатель – число уникальных респондентов, давших любой ответ по столбцовому вопросу.\n",
    "    \"\"\"\n",
    "    # Проверка типов\n",
    "    if rows_qs[\"type\"].nunique() > 1:\n",
    "        raise ValueError(\"Найденные вопросы для строк имеют разные типы (MULTI/SINGLE/MIX)\")\n",
    "    if cols_qs[\"type\"].nunique() > 1:\n",
    "        raise ValueError(\"Найденные вопросы для столбцов имеют разные типы (MULTI/SINGLE/MIX)\")\n",
    "\n",
    "    row_type = rows_qs[\"type\"].iloc[0] if not rows_qs.empty else None\n",
    "    col_type = cols_qs[\"type\"].iloc[0] if not cols_qs.empty else None\n",
    "\n",
    "    if row_type is None or col_type is None:\n",
    "        raise ValueError(\"Пустой набор вопросов для строк или столбцов\")\n",
    "\n",
    "    row_val_col = \"option\" if row_type == \"MULTI\" else \"answer\"\n",
    "    col_val_col = \"option\" if col_type == \"MULTI\" else \"answer\"\n",
    "\n",
    "    df_row = DB_filtered[DB_filtered[\"question\"].isin(rows_qs[\"question\"])]\n",
    "    df_col = DB_filtered[DB_filtered[\"question\"].isin(cols_qs[\"question\"])]\n",
    "\n",
    "    # Минимизация и устранение дублей на уровне (respondent_uid, wave, значение)\n",
    "    row_slim = (\n",
    "        df_row[[\"respondent_uid\", \"wave\", row_val_col]]\n",
    "        .dropna()\n",
    "        .drop_duplicates()\n",
    "        .rename(columns={row_val_col: \"row_val\"})\n",
    "    )\n",
    "    col_slim = (\n",
    "        df_col[[\"respondent_uid\", \"wave\", col_val_col]]\n",
    "        .dropna()\n",
    "        .drop_duplicates()\n",
    "        .rename(columns={col_val_col: \"col_val\"})\n",
    "    )\n",
    "\n",
    "    # Соединяем по респонденту и волне, получая все пары значений\n",
    "    pairs = pd.merge(row_slim, col_slim, on=[\"respondent_uid\", \"wave\"], how=\"inner\")\n",
    "\n",
    "    # Считаем уникальных респондентов в каждой ячейке\n",
    "    pivot = pd.pivot_table(\n",
    "        pairs,\n",
    "        index=\"row_val\",\n",
    "        columns=\"col_val\",\n",
    "        values=\"respondent_uid\",\n",
    "        aggfunc=\"nunique\", # type: ignore\n",
    "        fill_value=0,\n",
    "        observed=True,\n",
    "    ) # type: ignore\n",
    "\n",
    "    # Добавляем строку \"Всего\" по столбцам.\n",
    "    denom_by_col = col_slim.groupby(\"col_val\")[\"respondent_uid\"].nunique()\n",
    "    # Переупорядочим и заполним нулями для отсутствующих столбцов\n",
    "    denom_by_col = denom_by_col.reindex(pivot.columns, fill_value=0)\n",
    "    pivot.loc[\"Всего\", :] = denom_by_col\n",
    "    pivot.index.name = \"Ответы\"\n",
    "\n",
    "    # Проценты – как share по столбцам (без строки \"Всего\")\n",
    "    pivot_pct = pivot.drop(index=\"Всего\").divide(denom_by_col, axis=1)\n",
    "\n",
    "    return pivot, pivot_pct\n",
    "\n",
    "def build_pivot_tool(\n",
    "    DB: pd.DataFrame,\n",
    "    *,\n",
    "    # Строки сводной таблицы: один шаблон или список; exact=False трактует как contains\n",
    "    rows_query: str | Iterable[str],\n",
    "    rows_exact: bool = False,\n",
    "    # Фильтры вида [(question, value|\"CHECKED\", \"AND\"|\"OR\"), ...]\n",
    "    filters: Iterable[Tuple[str, str, Literal[\"AND\", \"OR\"]]] | None = None,\n",
    "    # Доп. фильтрация по волнам (актуальна и для columns=\"cross\")\n",
    "    waves: Iterable[str] | None = None,\n",
    "    # Столбцы сводной: \"wave\" (по умолчанию) или \"cross\"\n",
    "    columns: Literal[\"wave\", \"cross\"] = \"wave\",\n",
    "    # Для columns=\"cross\" – вопрос(ы) для столбцов\n",
    "    cols_query: str | Iterable[str] | None = None,\n",
    "    cols_exact: bool = False,\n",
    "    # Данные для кастом-фильтров (например, TOWNSIZE)\n",
    "    df_ext: pd.DataFrame | None = None,\n",
    "    # Управление форматом возврата\n",
    "    return_pct: bool = True,\n",
    "    as_json: bool = False,\n",
    "    verbose: int = 1,\n",
    ") -> dict[str, Any]:\n",
    "    # Служебная таблица вопросов и их типов\n",
    "    df_QS = DB[\"question\"].cat.categories.to_frame(name=\"question\")\n",
    "    df_QS[[\"type\", \"option\"]] = _get_q_type(df_QS[\"question\"])  # re-use существующую функцию\n",
    "\n",
    "    # Комбинируем фильтры\n",
    "    DB_filtered, applied_filters = _combine_filters(DB, df_QS, df_ext, filters, waves, verbose=verbose)\n",
    "    if DB_filtered is None:\n",
    "        return {\"pivot\": pd.DataFrame(), \"pivot_pct\": pd.DataFrame() if return_pct else None, \"meta\": {\"applied_filters\": [], \"rows\": [], \"cols\": [], \"waves\": list(waves) if waves is not None else None}}\n",
    "\n",
    "    # Выбор вопросов для строк\n",
    "    rows_qs = _select_questions(df_QS, rows_query, exact=rows_exact)\n",
    "    if rows_qs.empty:\n",
    "        raise ValueError(\"НЕ найдено вопросов, подходящих под rows_query\")\n",
    "\n",
    "    meta: dict[str, Any] = {\n",
    "        \"applied_filters\": applied_filters,\n",
    "        \"rows\": rows_qs[\"question\"].tolist(),\n",
    "        \"waves\": list(waves) if waves is not None else None,\n",
    "        \"mode\": columns,\n",
    "    }\n",
    "\n",
    "    if columns == \"wave\":\n",
    "        # Логика полностью делегируется _process_q (максимальное переиспользование кода)\n",
    "        if rows_qs[\"type\"].nunique() > 1:\n",
    "            raise ValueError(\"Найденные вопросы для строк имеют разные типы (MULTI/SINGLE/MIX)\")\n",
    "        q_type = \"SINGLE\" if rows_qs.shape[0] == 1 else rows_qs[\"type\"].iloc[0]\n",
    "        df_for_rows = DB_filtered[DB_filtered[\"question\"].isin(rows_qs[\"question\"])]\n",
    "        pivot, pivot_pct = _create_pivot_for_question(df_for_rows, df_QS, q_type)\n",
    "    else:\n",
    "        # columns == \"cross\"\n",
    "        if cols_query is None:\n",
    "            raise ValueError(\"Для columns='cross' необходимо указать cols_query\")\n",
    "        cols_qs = _select_questions(df_QS, cols_query, exact=cols_exact)\n",
    "        if cols_qs.empty:\n",
    "            raise ValueError(\"НЕ найдено вопросов, подходящих под cols_query\")\n",
    "        meta[\"cols\"] = cols_qs[\"question\"].tolist()\n",
    "        pivot, pivot_pct = _process_crosstab(DB_filtered, df_QS, rows_qs, cols_qs)\n",
    "\n",
    "    if not return_pct:\n",
    "        pivot_pct = None\n",
    "\n",
    "    if as_json:\n",
    "        out = {\n",
    "            \"pivot\": pivot.reset_index().to_dict(orient=\"records\"),\n",
    "            \"pivot_pct\": None if pivot_pct is None else pivot_pct.reset_index().to_dict(orient=\"records\"),\n",
    "            \"meta\": meta,\n",
    "        }\n",
    "    else:\n",
    "        out = {\"pivot\": pivot, \"pivot_pct\": pivot_pct, \"meta\": meta}\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50494b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = {\n",
    "  \"type\": \"function\",\n",
    "  \"function\": {\n",
    "    \"name\": \"build_pivot\",\n",
    "    \"description\": \"Построение сводной таблицы из данных опросов с фильтрацией и группировкой. Позволяет анализировать ответы респондентов по различным вопросам, применять фильтры и создавать кросстабуляции.\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"rows_query\": {\n",
    "          \"description\": \"Название вопроса(ов) для строк сводной таблицы. По умолчанию используется подстрока, если rows_exact=false\",\n",
    "          \"anyOf\": [\n",
    "            {\"type\": \"string\"},\n",
    "            {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "          ]\n",
    "        },\n",
    "        \"rows_exact\": {\n",
    "          \"type\": \"boolean\",\n",
    "          \"description\": \"Если true, точное совпадение названия вопроса. Если false, поиск по подстроке\",\n",
    "          \"default\": False\n",
    "        },\n",
    "        \"filters\": {\n",
    "          \"type\": \"array\",\n",
    "          \"items\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Вопрос или его часть для фильтрации\"\n",
    "              },\n",
    "              \"value\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Значение ответа для фильтра, или 'CHECKED' для множественного выбора\"\n",
    "              },\n",
    "              \"logic\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"AND\", \"OR\"],\n",
    "                \"description\": \"Логика комбинирования фильтров: AND или OR\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\"question\", \"value\", \"logic\"]\n",
    "          },\n",
    "          \"description\": \"Список фильтров для применения. Каждый фильтр задает вопрос, значение и логику AND/OR\"\n",
    "        },\n",
    "        \"waves\": {\n",
    "          \"type\": \"array\",\n",
    "          \"items\": {\"type\": \"string\"},\n",
    "          \"description\": \"Фильтрация данных по конкретным волнам (например, ['2024-01', '2025-01'])\"\n",
    "        },\n",
    "        \"columns\": {\n",
    "          \"type\": \"string\",\n",
    "          \"enum\": [\"wave\", \"cross\"],\n",
    "          \"description\": \"Режим столбцов: 'wave' группирует по волнам, 'cross' создает кросстаб с cols_query\",\n",
    "          \"default\": \"wave\"\n",
    "        },\n",
    "        \"cols_query\": {\n",
    "          \"description\": \"Название вопроса(ов) для столбцов при columns='cross'. Обязательно для режима кросстабуляции\",\n",
    "          \"anyOf\": [\n",
    "            {\"type\": \"string\"},\n",
    "            {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "          ]\n",
    "        },\n",
    "        \"cols_exact\": {\n",
    "          \"type\": \"boolean\",\n",
    "          \"description\": \"Если true, точное совпадение cols_query. Если False, поиск по подстроке\",\n",
    "          \"default\": False\n",
    "        }\n",
    "      },\n",
    "      \"required\": [\"rows_query\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1369f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"meta-llama/llama-3.3-70b-instruct:free\"\n",
    "model = \"meta-llama/llama-4-maverick:free\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            f\"Ты — аналитик данных. В твоем распоряжении есть база данных ответов респондентов на различные вопросы. \"\n",
    "            f\"Тебе дан пользовательский запрос - '{user_query}'.\\n\"\n",
    "            \"У тебя также есть контекст:\\n\\n{extract_text}\\n\\n\"\n",
    "            \"Твоя задача - пользуясь ТОЛЬКО контекстом, а также указанными инструментами, построить возможный план анализа. \"\n",
    "            f\"Точные формулировки допустимых вопросов для анализа - {chosen_qs}\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages, # type: ignore\n",
    "    tools=tools, # type: ignore\n",
    "    tool_choice=\"auto\",\n",
    "    max_tokens=4_000,\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "plan = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1509eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для выполнения запроса \"Посчитай мне размер средних сбережений и норму сбережений среди тех респондентов, у которых они есть\" на основе предоставленного контекста и доступных вопросов для анализа, можно составить следующий план:\n",
      "\n",
      "1. **Определить наличие сбережений**: Для начала необходимо определить, у каких респондентов есть сбережения. Это можно сделать с помощью вопроса '[A26] Каков размер денежных сбережений Вашей семьи (наличные деньги, депозиты в банках, ценные бумаги)?'. Респонденты с ненулевым размером сбережений считаются имеющими сбережения.\n",
      "\n",
      "2. **Фильтрация данных**: Отфильтровать данные, чтобы включить только респондентов с ненулевыми сбережениями.\n",
      "\n",
      "3. **Расчет среднего размера сбережений**: Используя отфильтрованные данные, рассчитать средний размер сбережений с помощью вопроса '[A26] Каков размер денежных сбережений Вашей семьи (наличные деньги, депозиты в банках, ценные бумаги)?'.\n",
      "\n",
      "4. **Расчет нормы сбережений**: Для расчета нормы сбережений использовать вопрос '[N4] Какой % от Вашего дохода Вы сберегаете ежемесячно?'. Рассчитать среднее значение этого процента среди респондентов с ненулевыми сбережениями.\n",
      "\n",
      "5. **Построение сводной таблицы**: Использовать функцию `build_pivot` для построения сводной таблицы, включающей средний размер сбережений и среднюю норму сбережений среди респондентов с ненулевыми сбережениями.\n",
      "\n",
      "Пример вызова функции:\n",
      "```python\n",
      "[build_pivot(rows_query='[A26] Каков размер денежных сбережений Вашей семьи (наличные деньги, депозиты в банках, ценные бумаги)?', \n",
      "             filters=[{'query': '[A26] Каков размер денежных сбережений Вашей семьи (наличные деньги, депозиты в банках, ценные бумаги)?', 'value': '!= 0', 'logic': 'AND'}], \n",
      "             columns='wave', \n",
      "             cols_query='', \n",
      "             cols_exact=False, \n",
      "             return_pct=False, \n",
      "             as_json=True, \n",
      "             verbose=1)]\n",
      "```\n",
      "Однако, для точного ответа на запрос, необходимо выполнить два отдельных расчета: один для среднего размера сбережений и другой для средней нормы сбережений. Поэтому, план будет включать два вызова `build_pivot` или один вызов с необходимыми параметрами для расчета обоих значений.\n",
      "\n",
      "Для размера средних сбережений:\n",
      "```python\n",
      "[build_pivot(rows_query='[A26] Каков размер денежных сбережений Вашей семьи (наличные деньги, депозиты в банках, ценные бумаги)?', \n",
      "             filters=[{'query': '[A26] Каков размер денежных сбережений Вашей семьи (наличные деньги, депозиты в банках, ценные бумаги)?', 'value': '> 0', 'logic': 'AND'}], \n",
      "             return_pct=False, \n",
      "             as_json=True, \n",
      "             verbose=1)]\n",
      "```\n",
      "\n",
      "Для нормы сбережений:\n",
      "```python\n",
      "[build_pivot(rows_query='[N4] Какой % от Вашего дохода Вы сберегаете ежемесячно?', \n",
      "             filters=[{'query': '[A26] Каков размер денежных сбережений Вашей семьи (наличные деньги, депозиты в банках, ценные бумаги)?', 'value': '> 0', 'logic': 'AND'}], \n",
      "             return_pct=False, \n",
      "             as_json=True, \n",
      "             verbose=1)]\n",
      "```\n",
      "\n",
      "Этот план позволит получить необходимые данные для ответа на пользовательский запрос.\n"
     ]
    }
   ],
   "source": [
    "print(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6282e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"meta-llama/llama-4-maverick:free\"\n",
    "model = \"meta-llama/llama-3.3-70b-instruct:free\"\n",
    "\n",
    "questions_block = \"\\n\".join(f\"{i+1}. {q}\" for i, q in enumerate(chosen_qs))\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            f\"Ты — агент по вызову функций. У тебя есть составленный план:\\n{plan}\\n\"\n",
    "            \"Соверши указанные в нем вызовы функций, которые тебе доступны. \"\n",
    "            f\"Точные формулировки доступных вопросов:\\n{questions_block}\"\n",
    "            \"\\nПроверяй JSON на валидность!\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages, # type: ignore\n",
    "    tools=tools, # type: ignore\n",
    "    tool_choice=\"auto\",\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "486d0009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='\\n 1}</function>', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_c0ahlELgpsxxvOCECRNyo3mM', function=Function(arguments='{\"rows_query\": \"[A26] \\\\u041a\\\\u0430\\\\u043a\\\\u043e\\\\u0432 \\\\u0440\\\\u0430\\\\u0437\\\\u043c\\\\u0435\\\\u0440 \\\\u0434\\\\u0435\\\\u043d\\\\u0435\\\\u0436\\\\u043d\\\\u044b\\\\u0445 \\\\u0441\\\\u0431\\\\u0435\\\\u0440\\\\u0435\\\\u0436\\\\u0435\\\\u043d\\\\u0438\\\\u0439 \\\\u0412\\\\u0430\\\\u0448\\\\u0435\\\\u0439 \\\\u0441\\\\u0435\\\\u043c\\\\u044c\\\\u0438 (\\\\u043d\\\\u0430\\\\u043b\\\\u0438\\\\u0447\\\\u043d\\\\u044b\\\\u0435 \\\\u0434\\\\u0435\\\\u043d\\\\u044c\\\\u0433\\\\u0438, \\\\u0434\\\\u0435\\\\u043f\\\\u043e\\\\u0437\\\\u0438\\\\u0442\\\\u044b \\\\u0432 \\\\u0431\\\\u0430\\\\u043d\\\\u043a\\\\u0430\\\\u0445, \\\\u0446\\\\u0435\\\\u043d\\\\u043d\\\\u044b\\\\u0435 \\\\u0431\\\\u0443\\\\u043c\\\\u0430\\\\u0433\\\\u0438)?\", \"filters\": [{\"query\": \"[A26] \\\\u041a\\\\u0430\\\\u043a\\\\u043e\\\\u0432 \\\\u0440\\\\u0430\\\\u0437\\\\u043c\\\\u0435\\\\u0440 \\\\u0434\\\\u0435\\\\u043d\\\\u0435\\\\u0436\\\\u043d\\\\u044b\\\\u0445 \\\\u0441\\\\u0431\\\\u0435\\\\u0440\\\\u0435\\\\u0436\\\\u0435\\\\u043d\\\\u0438\\\\u0439 \\\\u0412\\\\u0430\\\\u0448\\\\u0435\\\\u0439 \\\\u0441\\\\u0435\\\\u043c\\\\u044c\\\\u0438 (\\\\u043d\\\\u0430\\\\u043b\\\\u0438\\\\u0447\\\\u043d\\\\u044b\\\\u0435 \\\\u0434\\\\u0435\\\\u043d\\\\u044c\\\\u0433\\\\u0438, \\\\u0434\\\\u0435\\\\u043f\\\\u043e\\\\u0437\\\\u0438\\\\u0442\\\\u044b \\\\u0432 \\\\u0431\\\\u0430\\\\u043d\\\\u043a\\\\u0430\\\\u0445, \\\\u0446\\\\u0435\\\\u043d\\\\u043d\\\\u044b\\\\u0435 \\\\u0431\\\\u0443\\\\u043c\\\\u0430\\\\u0433\\\\u0438)?\", \"value\": \"> 0\", \"logic\": \"AND\"}], \"return_pct\": false, \"as_json\": true, \"verbose\": 1}', name='build_pivot'), type='function', index=0), ChatCompletionMessageFunctionToolCall(id='call_D2tHwYYP9Gi5FDtoHXpyRcQH', function=Function(arguments='{\"rows_query\": \"[N4] \\\\u041a\\\\u0430\\\\u043a\\\\u043e\\\\u0439 % \\\\u043e\\\\u0442 \\\\u0412\\\\u0430\\\\u0448\\\\u0435\\\\u0433\\\\u043e \\\\u0434\\\\u043e\\\\u0445\\\\u043e\\\\u0434\\\\u0430 \\\\u0412\\\\u044b \\\\u0441\\\\u0431\\\\u0435\\\\u0440\\\\u0435\\\\u0433\\\\u0430\\\\u0435\\\\u0442\\\\u0435 \\\\u0435\\\\u0436\\\\u0435\\\\u043c\\\\u0435\\\\u0441\\\\u044f\\\\u0447\\\\u043d\\\\u043e?\", \"filters\": [{\"query\": \"[A26] \\\\u041a\\\\u0430\\\\u043a\\\\u043e\\\\u0432 \\\\u0440\\\\u0430\\\\u0437\\\\u043c\\\\u0435\\\\u0440 \\\\u0434\\\\u0435\\\\u043d\\\\u0435\\\\u0436\\\\u043d\\\\u044b\\\\u0445 \\\\u0441\\\\u0431\\\\u0435\\\\u0440\\\\u0435\\\\u0436\\\\u0435\\\\u043d\\\\u0438\\\\u0439 \\\\u0412\\\\u0430\\\\u0448\\\\u0435\\\\u0439 \\\\u0441\\\\u0435\\\\u043c\\\\u044c\\\\u0438 (\\\\u043d\\\\u0430\\\\u043b\\\\u0438\\\\u0447\\\\u043d\\\\u044b\\\\u0435 \\\\u0434\\\\u0435\\\\u043d\\\\u044c\\\\u0433\\\\u0438, \\\\u0434\\\\u0435\\\\u043f\\\\u043e\\\\u0437\\\\u0438\\\\u0442\\\\u044b \\\\u0432 \\\\u0431\\\\u0430\\\\u043d\\\\u043a\\\\u0430\\\\u0445, \\\\u0446\\\\u0435\\\\u043d\\\\u043d\\\\u044b\\\\u0435 \\\\u0431\\\\u0443\\\\u043c\\\\u0430\\\\u0433\\\\u0438)?\", \"value\": \"> 0\", \"logic\": \"AND\"}], \"return_pct\": false, \"as_json\": true, \"verbose\": 1}', name='build_pivot'), type='function', index=1)], reasoning=None)\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d52861db",
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTIONS_MAPPER = {\n",
    "    \"build_pivot\": build_pivot_tool\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "666e2b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"rows_query\": \"[A26] \\u041a\\u0430\\u043a\\u043e\\u0432 \\u0440\\u0430\\u0437\\u043c\\u0435\\u0440 \\u0434\\u0435\\u043d\\u0435\\u0436\\u043d\\u044b\\u0445 \\u0441\\u0431\\u0435\\u0440\\u0435\\u0436\\u0435\\u043d\\u0438\\u0439 \\u0412\\u0430\\u0448\\u0435\\u0439 \\u0441\\u0435\\u043c\\u044c\\u0438 (\\u043d\\u0430\\u043b\\u0438\\u0447\\u043d\\u044b\\u0435 \\u0434\\u0435\\u043d\\u044c\\u0433\\u0438, \\u0434\\u0435\\u043f\\u043e\\u0437\\u0438\\u0442\\u044b \\u0432 \\u0431\\u0430\\u043d\\u043a\\u0430\\u0445, \\u0446\\u0435\\u043d\\u043d\\u044b\\u0435 \\u0431\\u0443\\u043c\\u0430\\u0433\\u0438)?\", \"filters\": [{\"query\": \"[A26] \\u041a\\u0430\\u043a\\u043e\\u0432 \\u0440\\u0430\\u0437\\u043c\\u0435\\u0440 \\u0434\\u0435\\u043d\\u0435\\u0436\\u043d\\u044b\\u0445 \\u0441\\u0431\\u0435\\u0440\\u0435\\u0436\\u0435\\u043d\\u0438\\u0439 \\u0412\\u0430\\u0448\\u0435\\u0439 \\u0441\\u0435\\u043c\\u044c\\u0438 (\\u043d\\u0430\\u043b\\u0438\\u0447\\u043d\\u044b\\u0435 \\u0434\\u0435\\u043d\\u044c\\u0433\\u0438, \\u0434\\u0435\\u043f\\u043e\\u0437\\u0438\\u0442\\u044b \\u0432 \\u0431\\u0430\\u043d\\u043a\\u0430\\u0445, \\u0446\\u0435\\u043d\\u043d\\u044b\\u0435 \\u0431\\u0443\\u043c\\u0430\\u0433\\u0438)?\", \"value\": \"> 0\", \"logic\": \"AND\"}], \"return_pct\": false, \"as_json\": true, \"verbose\": 1}\n",
      "!!! Значение '> 0' для вопроса '[A26] Каков размер денежных сбережений Вашей семьи (наличные деньги, депозиты в банках, ценные бумаги)?' не найдено в базе данных\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "msg = response.choices[0].message\n",
    "\n",
    "if msg.tool_calls:\n",
    "    fn = msg.tool_calls[0].function     # Только первый tool call\n",
    "    if fn.name in FUNCTIONS_MAPPER:\n",
    "        called_fn = FUNCTIONS_MAPPER[fn.name]\n",
    "        print(fn.arguments)\n",
    "        args = json.loads(fn.arguments or \"{}\")\n",
    "\n",
    "        filters = None\n",
    "        if args.get(\"filters\"):\n",
    "            filters = [\n",
    "                (f[\"query\"], f[\"value\"], f[\"logic\"]) \n",
    "                for f in args[\"filters\"]\n",
    "            ]\n",
    "        \n",
    "        res = called_fn(\n",
    "            df,\n",
    "            rows_query=args[\"rows_query\"],\n",
    "            columns=args.get(\"columns\", \"wave\"),\n",
    "            filters=filters,\n",
    "            waves=args.get(\"waves\"),\n",
    "            cols_query=args.get(\"cols_query\"),\n",
    "            rows_exact=args.get(\"rows_exact\", False),\n",
    "            cols_exact=args.get(\"cols_exact\", False),\n",
    "            return_pct=args.get(\"return_pct\", True),\n",
    "            as_json=True,\n",
    "            verbose=args.get(\"verbose\", 1),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dcd9a916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pivot': Empty DataFrame\n",
       " Columns: []\n",
       " Index: [],\n",
       " 'pivot_pct': None,\n",
       " 'meta': {'applied_filters': [], 'rows': [], 'cols': [], 'waves': None}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
